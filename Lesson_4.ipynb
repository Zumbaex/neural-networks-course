{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYMkQZHUyIfm",
        "outputId": "cc508b13-06d1-407e-ba50-1226b54250b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-5ccbb8cfd211>:48: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "781/781 [==============================] - 112s 99ms/step - loss: 144.0063 - accuracy: 0.0219 - val_loss: 153.8680 - val_accuracy: 0.0057\n",
            "Epoch 2/2\n",
            "781/781 [==============================] - 66s 85ms/step - loss: 125.7398 - accuracy: 0.0000e+00 - val_loss: 131.1112 - val_accuracy: 0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-5ccbb8cfd211>:55: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  score = model.evaluate_generator(test_generator, steps=len(x_test) // batch_size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 131.27549743652344\n",
            "Test accuracy: 0.0023036859929561615\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.applications import ResNet50\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "# Установка параметров нейросети\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "# Загрузка данных ImageNet\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Создание объекта ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                             rotation_range=10,\n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=False,\n",
        "                             vertical_flip=False)\n",
        "\n",
        "# Создание генераторов для обучающей и тестовой выборок\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "test_generator = datagen.flow(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "# Создание предварительно обученной модели ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Создание модели для Featurization\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=len(x_test) // batch_size)\n",
        "\n",
        "# Оценка производительности модели на тестовых данных\n",
        "score = model.evaluate_generator(test_generator, steps=len(x_test) // batch_size)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы:**\n",
        "- Не совсем понял отражаемую статистику при использовании оптимизатора **Adam** (loss: 149955.2500 - accuracy: 0.0000e+00 - val_loss: 185992.7500 - val_accuracy: 0.0000e+00), точность оказалась очень мала на двух эпохах.\n",
        "- В связи с тем, что **Adam** не справлялся с задачей, я заменил его на **SGD**, оказалось, что для достижения результата в точности 0.87+ достаточно одной эпохи с батчами равными 64 на этом оптимизаторе. Почему такая разница?\n",
        "- Еще мне оказалось непонятно, почему указано в количестве классов в уроке в последней нейронке 1000 (num_classes = 1000), если в **cifar10** их соответственно 10?\n",
        "- Кстати интересно, когда поменял на корректное количество классов, оптимизатор **Adam** заработал лучше, но точность у него оказалась все равно гораздо ниже чем у **SGD**."
      ],
      "metadata": {
        "id": "MxqrqvbSGroP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2 задание:**\n",
        "- Если говорить о **Mnist**, то надо было бы поменять количество каналов, и в целом можно было бы поиграться с дата-генератором, насчет входа не совсем понял, mnist содержит фото 28 на 28, но Resnet принимает на вход 224 на 224, в таком случае вход остается (224, 224, 1)?\n",
        "- Если говорить о **Cifar100**, то пришлось бы в целом поменять только количество классов с 10 на 100.\n",
        "- А вот насчет **IMAGENET** я не знаю, потому что этот датасет насколько я понял является мультиклассовым (картинки могут содержать разные объекты), в данном случае как надо изменить параметры, т.е. что делать с количеством классов например?"
      ],
      "metadata": {
        "id": "N8LPSkZXMiD7"
      }
    }
  ]
}